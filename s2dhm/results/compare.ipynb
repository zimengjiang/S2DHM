{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['npgradient_huber_loss_cmu_slice_2.npy', 'cauchy_loss_cmu_slice_2.npy', 'huber_loss_cmu_slice_2.npy', 'npgradient_sqloss_cmu_slice_2.npy', 'npgradient_gm_loss_cmu_slice_2.npy', 'gm_loss_cmu_slice_2.npy', 'sqloss_cmu_slice_2.npy', 'npgradient_cauchy_loss_cmu_slice_2.npy']\n"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fnames = [fname for fname in os.listdir(\"./\") if \".ipynb\" not in fname]\n",
    "print(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "init_num_inliers (382, 5)\n[2 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 4 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 4 0 0 0\n 1 1 0 0 0 0 0 0 0 0 3 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 3 1 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0\n 1 1 0 0 0 0 0 0 2 0 0 1 1 1 1 1 2 1 0 0 0 0 0 0 1 3 2 0 0 0 0 0 0 0 0 0 0\n 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 2 0 1 0 2 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n 0 0 0 1 1 0 3 2 0 1 1 1 0 2 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 2 0 2 0 0 0 0 3 0 0 0 0\n 0 1 0 0 0 0 1 1 0 0 0 0]\n(382, 1)\nTrue\ninit_pose_error (382, 5, 2)\n(382, 1, 2)\nfpnp_num_inliers (382, 5)\n[2 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 4 1 2 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 4 0 0 0\n 1 1 0 0 0 0 0 0 0 0 3 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 3 1 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0\n 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 2 1 0 0 0 0 0 0 1 3 2 0 0 0 0 0 0 0 0 0 0\n 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 2 0 1 0 2 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n 0 0 0 1 1 0 3 2 0 1 0 1 0 2 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 2 0 2 0 0 0 0 3 0 0 0 0\n 0 0 0 0 0 0 1 1 0 0 0 0]\n(382, 1)\nTrue\nfpnp_pose_error (382, 5, 2)\n(382, 1, 2)\n"
    }
   ],
   "source": [
    "for fname in fnames:\n",
    "    array_dict = np.load(fname)[()]\n",
    "    for key in array_dict.keys():\n",
    "        print(key, array_dict[key].shape)\n",
    "        num_images = array_dict[key].shape[0]\n",
    "        if \"inliers\" in key:\n",
    "            best_idxs = np.argmax(array_dict[key], axis=1)\n",
    "            print(best_idxs)\n",
    "            gt = np.amax(array_dict[key], axis=1)\n",
    "            # print(np.amax(array_dict[key], axis=1))\n",
    "            myresult = array_dict[key][np.arange(num_images), best_idxs]\n",
    "            print(myresult[:, None].shape)\n",
    "            print(np.all(gt == myresult))\n",
    "        else:\n",
    "            # gt = np.amax(array_dict[key], axis=1)\n",
    "            # print(np.amax(array_dict[key], axis=1))\n",
    "            myresult = array_dict[key][np.arange(num_images), best_idxs, :][:, None, :]\n",
    "            print(myresult.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_prediction(array_dict):\n",
    "    num_images = array_dict['init_num_inliers'].shape[0]\n",
    "    # k = 5\n",
    "    new_array_dict = {}\n",
    "    best_init_idx = np.argmax(array_dict['init_num_inliers'], axis=1)\n",
    "    new_array_dict['init_num_inliers'] = array_dict['init_num_inliers'][np.arange(num_images), best_idxs][:, None]\n",
    "    new_array_dict['init_pose_error'] = array_dict['init_pose_error'][np.arange(num_images), best_idxs][:, None, :]\n",
    "    new_array_dict['fpnp_num_inliers'] = array_dict['fpnp_num_inliers'][np.arange(num_images), best_idxs][:, None]\n",
    "    new_array_dict['fpnp_pose_error'] = array_dict['fpnp_pose_error'][np.arange(num_images), best_idxs][:, None, :]\n",
    "    return new_array_dict\n",
    "    # best_init_inliers = np.zeros((num_images, 1))\n",
    "    # best_init_pose_error = np.zeros((num_images, 1, 2))\n",
    "    # best_init_inliers = np.zeros((num_images, 1))\n",
    "    # best_init_pose_error = np.zeros((num_images, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(array_dict):\n",
    "    stats = {}\n",
    "    array_dict = choose_best_prediction(array_dict)\n",
    "    rPnP_inliers = array_dict['init_num_inliers']\n",
    "    fPnP_inliers = array_dict['fpnp_num_inliers']\n",
    "    rPnP_perror = array_dict['init_pose_error']\n",
    "    fPnP_perror = array_dict['fpnp_pose_error']\n",
    "    rPnP_rerror = array_dict['init_pose_error'][:, :, 0]\n",
    "    fPnP_rerror = array_dict['fpnp_pose_error'][:, :, 0]\n",
    "    rPnP_terror = array_dict['init_pose_error'][:, :, 1]\n",
    "    fPnP_terror = array_dict['fpnp_pose_error'][:, :, 1]\n",
    "\n",
    "    rPnP_high_prec = np.logical_and(rPnP_rerror < 2, rPnP_terror < 0.25)\n",
    "    fPnP_high_prec = np.logical_and(fPnP_rerror < 2, fPnP_terror < 0.25)\n",
    "    rPnP_medium_prec = np.logical_and(rPnP_rerror < 5, rPnP_terror < 0.5)\n",
    "    fPnP_medium_prec = np.logical_and(fPnP_rerror < 5, fPnP_terror < 0.5)\n",
    "    rPnP_coarse_prec = np.logical_and(rPnP_rerror < 10, rPnP_terror < 5)\n",
    "    fPnP_coarse_prec = np.logical_and(fPnP_rerror < 10, fPnP_terror < 5)\n",
    "\n",
    "    # stats['mean_rPnP_num_inliers'] = np.mean(array_dict['init_num_inliers'])\n",
    "    # stats['mean_rPnP_rerror'] = np.mean(array_dict['init_pose_error'][:, :, 0])\n",
    "    # stats['mean_rPnP_terror'] = np.mean(array_dict['init_pose_error'][:, :, 1])\n",
    "    stats['mean_fPnP_num_inliers'] = np.mean(array_dict['fpnp_num_inliers'])\n",
    "    stats['mean_fPnP_rerror'] = np.mean(array_dict['fpnp_pose_error'][:, :, 0])\n",
    "    stats['mean_fPnP_terror'] = np.mean(array_dict['fpnp_pose_error'][:, :, 1])\n",
    "    # stats['mean_top1_rPnP_num_inliers'] = np.mean(rPnP_inliers, axis=0)[0]\n",
    "    # stats['mean_top1_fPnP_num_inliers'] = np.mean(fPnP_inliers, axis=0)[0]\n",
    "    # stats['mean_top1_rPnP_pose_error'] = np.mean(rPnP_perror, axis=0)[0] \n",
    "    # stats['mean_top1_fPnP_pose_error'] = np.mean(fPnP_perror, axis=0)[0]\n",
    "    # stats['rPnP_high_prec'] = np.mean(rPnP_high_prec, axis=0)[0]\n",
    "    stats['fPnP_high_prec'] = np.mean(fPnP_high_prec, axis=0)[0]\n",
    "    # stats['rPnP_medium_prec'] = np.mean(rPnP_medium_prec, axis=0)[0]\n",
    "    stats['fPnP_medium_prec'] = np.mean(fPnP_medium_prec, axis=0)[0]\n",
    "    # stats['rPnP_coarse_prec'] = np.mean(rPnP_coarse_prec, axis=0)[0]\n",
    "    stats['fPnP_coarse_prec'] = np.mean(fPnP_coarse_prec, axis=0)[0]\n",
    "    for key in stats.keys():\n",
    "        print(\"{}: {:.3f}\".format(key, stats[key]))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "npgradient_huber_loss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 469.136\nmean_fPnP_rerror: 0.147\nmean_fPnP_terror: 0.351\nfPnP_high_prec: 0.435\nfPnP_medium_prec: 0.804\nfPnP_coarse_prec: 1.000\ncauchy_loss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 466.733\nmean_fPnP_rerror: 0.187\nmean_fPnP_terror: 0.449\nfPnP_high_prec: 0.298\nfPnP_medium_prec: 0.691\nfPnP_coarse_prec: 1.000\nhuber_loss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 466.976\nmean_fPnP_rerror: 0.187\nmean_fPnP_terror: 0.447\nfPnP_high_prec: 0.306\nfPnP_medium_prec: 0.707\nfPnP_coarse_prec: 1.000\nnpgradient_sqloss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 469.094\nmean_fPnP_rerror: 0.148\nmean_fPnP_terror: 0.353\nfPnP_high_prec: 0.437\nfPnP_medium_prec: 0.804\nfPnP_coarse_prec: 1.000\nnpgradient_gm_loss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 468.961\nmean_fPnP_rerror: 0.148\nmean_fPnP_terror: 0.358\nfPnP_high_prec: 0.440\nfPnP_medium_prec: 0.791\nfPnP_coarse_prec: 1.000\ngm_loss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 466.825\nmean_fPnP_rerror: 0.187\nmean_fPnP_terror: 0.450\nfPnP_high_prec: 0.301\nfPnP_medium_prec: 0.699\nfPnP_coarse_prec: 1.000\nsqloss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 467.013\nmean_fPnP_rerror: 0.188\nmean_fPnP_terror: 0.449\nfPnP_high_prec: 0.309\nfPnP_medium_prec: 0.707\nfPnP_coarse_prec: 1.000\nnpgradient_cauchy_loss_cmu_slice_2.npy\nmean_fPnP_num_inliers: 468.869\nmean_fPnP_rerror: 0.148\nmean_fPnP_terror: 0.360\nfPnP_high_prec: 0.429\nfPnP_medium_prec: 0.793\nfPnP_coarse_prec: 1.000\n"
    }
   ],
   "source": [
    "for fname in fnames:\n",
    "    array_dict = np.load(fname)[()]\n",
    "    print(fname)\n",
    "    calculate_stats(array_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bits2dcondaba86b0ea9c4040118f74f4f5c42c074e",
   "display_name": "Python 3.7.6 64-bit ('s2d': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}